import gradio as gr
from core.translator import Translator
from core.text_processing import TextProcessor
from core.generator import ImageGenerator
from core.storyteller import StoryTeller
from core.prompt_engineering import PromptEngineer
from core.session_manager import SessionManager
from utils.config import config
from utils.logger import app_logger
import os
import random
import uuid

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π
translator = Translator()
text_processor = TextProcessor()
generator = ImageGenerator(low_memory_mode=True)  # Enable low memory mode for 8GB RAM
storyteller = StoryTeller(model_name="ai-forever/rugpt3small_based_on_gpt2", device="cpu") 
prompt_engineer = PromptEngineer()
session_manager = SessionManager(storage_path=config.get("paths.sessions_dir", "sessions"))

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
class SessionState:
    def __init__(self):
        self.session_id = str(uuid.uuid4())
        self.history = ""
        self.current_seed = -1
        self.char_desc = ""
        self.style = ""
        self.images = []
        self.educational_mode = False

    def reset(self):
        self.session_id = str(uuid.uuid4())
        self.history = ""
        self.current_seed = random.randint(0, 1000000) if not self.educational_mode else self.current_seed
        self.char_desc = ""
        self.style = ""
        self.images = []

session = SessionState()

def generate_sequence(base_prompt_ru, character, style, count=3, educational_mode=False):
    """Generates a sequence of related images."""
    images = []
    
    # Base extraction
    visual_text = text_processor.extract_visual_part(base_prompt_ru)
    
    # Check if this is a long user story/plot (Comic Mode)
    # If the input text is long (> 50 chars) and contains spaces, we treat it as a direct storyboard script
    if len(base_prompt_ru) > 50 and base_prompt_ru.count(' ') > 5:
        app_logger.info(f"Detected long story input. Splitting into scenes...")
        variations = text_processor.split_story_into_scenes(base_prompt_ru, num_scenes=count)
    
    # IT-specific variations based on style and content
    # Dynamic Storyboard Generation (Preferred for Educational)
    elif educational_mode:
        # Use LLM to generate a coherent storyboard
        app_logger.info(f"Generating storyboard for: {character} using style {style}")
        variations = storyteller.generate_visual_storyboard(character, style, count)
        if not variations or len(variations) < count:
             # Fallback to hardcoded list if LLM fails
             variations = ["informational diagram", "detailed schematic", "process flow", "summary result"]
    elif style == "Algorithm Flowchart":
        # ... (Old hardcoded logic as backup or for non-educational mode)
        variations = [
            "flowchart diagram with start/stop ovals",
            "pseudocode structure",
            "trace table",
            "call stack hierarchy"
        ]
    else:
        variations = ["cinematic shot", "action shot, dynamic", "close up"]
    
    for i in range(count):
        variation = variations[i % len(variations)]
        
        complex_prompt, negative_prompt = prompt_engineer.build_prompt(
            base_description=f"{visual_text}, {variation}", 
            style_name=style, 
            character_desc=character,
            add_random_camera=False,
            educational_mode=educational_mode
        )
        
        en_prompt = translator.translate(complex_prompt)
        en_negative_prompt = translator.translate(negative_prompt) if negative_prompt else ""
        app_logger.info(f"Generating frame {i+1}: {en_prompt}")
        if en_negative_prompt:
            app_logger.info(f"Negative prompt: {en_negative_prompt}")
        
        # Use varied seed for each scene (base seed + scene index) for diversity
        scene_seed = session.current_seed + i if session.current_seed != -1 else None
        img = generator.generate(en_prompt, negative_prompt=en_negative_prompt, seed=scene_seed, educational_mode=educational_mode)
        images.append(img)
        
    return images

def start_story(character_input, style_input, educational_mode, scene_count):
    """Initializes the story session."""
    session.reset()
    session.char_desc = character_input
    session.style = style_input
    session.educational_mode = educational_mode
    
    app_logger.info(f"Starting new session: {session.session_id}")
    app_logger.info(f"Character: {character_input}, Style: {style_input}, Educational: {educational_mode}, Scenes: {scene_count}")
    
    # Smart Detection: Is this a Story or a Topic?
    is_narrative = len(character_input) > 50 and character_input.count(' ') > 5
    
    if is_narrative:
        # Narrative Mode: Visualize the user's text directly!
        intro_text = character_input
        session.history = f"–°–∏—Å—Ç–µ–º–∞: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—é–∂–µ—Ç–∞.\n–°—é–∂–µ—Ç: {character_input}"
        # We don't ask the LLM to generate text, we just say "Here is your visualization"
        chat_output = "–ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Ä—è–¥ –ø–æ –≤–∞—à–µ–º—É —Å—é–∂–µ—Ç—É..."
        
        # Determine strict mode for prompt engineering based on style
        # If Comic Book, we want to enforce it even if Educational is checked
        if style_input == "Comic Book":
             # We might want to pass educational_mode=False to generate_sequence to avoid "simple background" logic
             # But let's handle that in PromptEngineer mostly.
             pass
    else:
        # Topic Mode: Generate educational intro
        if educational_mode:
            intro_prompt = f"–¢–µ–º–∞ –∑–∞–Ω—è—Ç–∏—è: {character_input}. –°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è: {style_input}. –í–≤–µ–¥–µ–Ω–∏–µ:"
            intro_text = storyteller.generate_response("–õ–µ–∫—Ü–∏—è –Ω–∞—á–∞–ª–∞—Å—å.", intro_prompt, educational_mode=True)
            session.history = f"–°–∏—Å—Ç–µ–º–∞: –ó–∞–Ω—è—Ç–∏–µ –Ω–∞ —Ç–µ–º—É '{character_input}'.\n–õ–µ–∫—Ç–æ—Ä: {intro_text}"
        else:
            intro_prompt = f"–ò—Å—Ç–æ—Ä–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è. –ì–ª–∞–≤–Ω—ã–π –≥–µ—Ä–æ–π: {character_input}. –ñ–∞–Ω—Ä: {style_input}. –ù–∞—á–∞–ª–æ:"
            intro_text = storyteller.generate_response("–í—Å—Ç—É–ø–ª–µ–Ω–∏–µ:", intro_prompt, educational_mode=False)
            session.history = f"–°–∏—Å—Ç–µ–º–∞: –ò—Å—Ç–æ—Ä–∏—è –æ {character_input}.\n–ú–∞—Å—Ç–µ—Ä: {intro_text}"
        chat_output = intro_text
    
    # Generate Sequence
    # IMPORTANT: If narrative, intro_text IS the narrative. If topic, intro_text IS the generated lecture.
    imgs = generate_sequence(intro_text, character_input, style_input, count=scene_count, educational_mode=educational_mode)
    session.images.extend(imgs)
    
    # Save session
    session_manager.save_session(
        session.session_id, 
        session.history, 
        session.char_desc, 
        session.style, 
        session.current_seed,
        session.educational_mode,
        images=session.images
    )
    
    # Return format: List of [User, Bot] dicts
    return [
        {"role": "assistant", "content": chat_output}
    ], imgs

def chat_turn(user_message, chat_history):
    """Handles a single turn of the chat."""
    if not user_message:
        return chat_history, None

    app_logger.info(f"User message: {user_message}")

    # Update history
    if session.educational_mode:
        session.history += f"\n–°—Ç—É–¥–µ–Ω—Ç: {user_message}"
    else:
        session.history += f"\n–ò–≥—Ä–æ–∫: {user_message}"
    
    # Generate Text Response
    response_text = storyteller.generate_response(session.history, user_message, educational_mode=session.educational_mode)
    
    if session.educational_mode:
        session.history += f"\n–õ–µ–∫—Ç–æ—Ä: {response_text}"
    else:
        session.history += f"\n–ú–∞—Å—Ç–µ—Ä: {response_text}"
    
    # Generate Sequence
    imgs = generate_sequence(response_text, session.char_desc, session.style, educational_mode=session.educational_mode)
    session.images.extend(imgs)
    
    # Update chat history
    chat_history.append({"role": "user", "content": user_message})
    chat_history.append({"role": "assistant", "content": response_text})
    
    # Save session
    session_manager.save_session(
        session.session_id, 
        session.history, 
        session.char_desc, 
        session.style, 
        session.current_seed,
        session.educational_mode,
        images=session.images
    )
    
    return chat_history, imgs

with gr.Blocks(title="Neuro Tale: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª–æ–≤", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üéì Neuro Tale: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–∑—É–∞–ª–æ–≤ –¥–ª—è IT-–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
    gr.Markdown("**–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É—á–µ–±–Ω–æ-–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ:**")
    gr.Markdown("- –ê–ª–≥–æ—Ä–∏—Ç–º–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é")
    gr.Markdown("- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö") 
    gr.Markdown("- –ú–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –∏ –ò–ò")
    gr.Markdown("- –†–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–º –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö")
    gr.Markdown("- –í–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")
    gr.Markdown("- –†–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤")
    
    with gr.Row():
        with gr.Column(scale=1):
            # Setup Column
            char_input = gr.Textbox(
                label="–¢–µ–º–∞ / –ö–æ–Ω—Ü–µ–ø—Ü–∏—è", 
                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–ê–ª–≥–æ—Ä–∏—Ç–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø—É–∑—ã—Ä—å–∫–æ–º', '–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏', '–°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'"
            )
            style_input = gr.Dropdown(
                label="–°—Ç–∏–ª—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", 
                choices=prompt_engineer.get_available_styles(), 
                value="Educational",
                info="–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Å—Ç–∏–ª—å –¥–ª—è IT-—Ç–µ–º—ã"
            )
            educational_checkbox = gr.Checkbox(
                label="–£—á–µ–±–Ω–æ-–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)", 
                value=True,
                info="–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–ª—è –ª–µ–∫—Ü–∏–π, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π –∏ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"
            )
            scene_count_slider = gr.Slider(
                label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                minimum=1,
                maximum=5,
                value=3,
                step=1,
                info="–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç 1 –¥–æ 5 —Å—Ü–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
            )
            low_memory_checkbox = gr.Checkbox(
                label="–†–µ–∂–∏–º –Ω–∏–∑–∫–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ (8GB RAM)", 
                value=False,
                info="–í–∫–ª—é—á–∏—Ç–µ –µ—Å–ª–∏ —É –≤–∞—Å 8GB –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏"
            )
            start_btn = gr.Button("üöÄ –°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å", variant="primary")
            
            # Current Scene Gallery
            scene_gallery = gr.Gallery(
                label="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å", 
                columns=[1], 
                rows=[3], 
                object_fit="contain", 
                height="auto"
            )
            
        with gr.Column(scale=2):
            # Chat Interface
            chatbot = gr.Chatbot(label="–ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –≤–∏–∑—É–∞–ª–∞–º", height=600)
            msg_input = gr.Textbox(
                label="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", 
                placeholder="–û–ø–∏—à–∏—Ç–µ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç–µ –¥–µ—Ç–∞–ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"
            )
            send_btn = gr.Button("–î–æ–ø–æ–ª–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å")

    # Events
    # Events
    start_btn.click(
        fn=start_story,
        inputs=[char_input, style_input, educational_checkbox, scene_count_slider],
        outputs=[chatbot, scene_gallery]
    )
    
    send_btn.click(
        fn=chat_turn,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, scene_gallery]
    )
    msg_input.submit(
        fn=chat_turn,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, scene_gallery]
    )

if __name__ == "__main__":
    demo.launch(share=True)
