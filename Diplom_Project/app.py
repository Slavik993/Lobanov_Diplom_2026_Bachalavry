import gradio as gr
from core.translator import Translator
from core.text_processing import TextProcessor
from core.generator import ImageGenerator
from core.storyteller import StoryTeller
from core.prompt_engineering import PromptEngineer
from core.session_manager import SessionManager
from utils.config import config
from utils.logger import app_logger
import os
import random
import uuid

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π
translator = Translator()
text_processor = TextProcessor()
generator = ImageGenerator(low_memory_mode=True)  # Enable low memory mode for 8GB RAM
storyteller = StoryTeller(model_name="ai-forever/rugpt3small_based_on_gpt2", device="cpu") 
prompt_engineer = PromptEngineer()
session_manager = SessionManager(storage_path=config.get("paths.sessions_dir", "sessions"))

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
class SessionState:
    def __init__(self):
        self.session_id = str(uuid.uuid4())
        self.history = ""
        self.current_seed = -1
        self.char_desc = ""
        self.style = ""
        self.images = []
        self.educational_mode = False

    def reset(self):
        self.session_id = str(uuid.uuid4())
        self.history = ""
        self.current_seed = random.randint(0, 1000000) if not self.educational_mode else self.current_seed
        self.char_desc = ""
        self.style = ""
        self.images = []

session = SessionState()

def generate_sequence(base_prompt_ru, character, style, count=3, educational_mode=False):
    """Generates a sequence of related images."""
    images = []
    
    # Base extraction
    visual_text = text_processor.extract_visual_part(base_prompt_ru)
    
    # IT-specific variations based on style and content
    base_content = base_prompt_ru.lower()
    if style == "Algorithm Flowchart":
        if "–ø—É–∑—ã—Ä—å–∫" in base_content or "bubble" in base_content:
            variations = [
                "bubble sort initialization: array declaration, start rectangle, arrow to loop",
                "bubble sort outer loop: for i from 0 to n-1, loop diamond, counter variable",
                "bubble sort inner loop: for j from 0 to n-i-1, nested loop structure",
                "bubble sort comparison: if array[j] > array[j+1], decision diamond, comparison operator",
                "bubble sort swap: exchange elements, swap operation rectangle, temporary variable",
                "bubble sort pass completion: end of inner loop, arrow back to outer loop",
                "bubble sort algorithm termination: end rectangle, sorted array result",
                "bubble sort time complexity: O(n¬≤) notation, complexity analysis diagram"
            ]
        elif "–±—ã—Å—Ç—Ä" in base_content or "quick" in base_content:
            variations = [
                "quick sort function call: sort(array, low, high), start rectangle, parameters",
                "quick sort base case: if low >= high, return, decision diamond",
                "quick sort pivot selection: choose pivot element, pivot assignment rectangle",
                "quick sort partitioning: rearrange elements around pivot, partition function call",
                "quick sort left subarray: recursive call sort(left), recursive arrow",
                "quick sort right subarray: recursive call sort(right), recursive arrow",
                "quick sort completion: all subarrays sorted, end rectangle",
                "quick sort complexity: O(n log n) average case, complexity diagram"
            ]
        else:
            variations = ["initialization step", "main processing loop", "decision making", "final output"]
    elif style == "Database Schema":
        variations = ["entity definition", "relationship mapping", "table structure", "query example"]
    elif style == "Neural Network":
        variations = ["input layer", "hidden layers", "output layer", "training process"]
    elif style == "Web Interface":
        variations = ["homepage layout", "user dashboard", "form design", "navigation flow"]
    elif style == "Code Structure":
        variations = ["class diagram", "module dependencies", "data flow", "architecture overview"]
    elif educational_mode:
        variations = ["establishing shot, diagram", "detailed step, labeled", "summary view, schematic"]
    else:
        variations = ["cinematic shot", "action shot, dynamic", "close up, detailed expression"]
    
    # Adjust style for IT themes
    if any(keyword in base_prompt_ru.lower() for keyword in ["–∞–ª–≥–æ—Ä–∏—Ç–º", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "–∫–æ–¥", "code", "algorithm"]):
        style = "Algorithm Flowchart" if style == "Educational" else style
    elif any(keyword in base_prompt_ru.lower() for keyword in ["–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö", "database", "sql", "—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è"]):
        style = "Database Schema" if style == "Educational" else style
    elif any(keyword in base_prompt_ru.lower() for keyword in ["–Ω–µ–π—Ä–æ–Ω", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "ml", "ai", "neural"]):
        style = "Neural Network" if style == "Educational" else style
    elif any(keyword in base_prompt_ru.lower() for keyword in ["–≤–µ–±", "–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å", "ui", "ux", "web"]):
        style = "Web Interface" if style == "Educational" else style
    
    for i in range(count):
        variation = variations[i % len(variations)]
        
        complex_prompt, negative_prompt = prompt_engineer.build_prompt(
            base_description=f"{visual_text}, {variation}", 
            style_name=style, 
            character_desc=character,
            add_random_camera=False,
            educational_mode=educational_mode
        )
        
        en_prompt = translator.translate(complex_prompt)
        en_negative_prompt = translator.translate(negative_prompt) if negative_prompt else ""
        app_logger.info(f"Generating frame {i+1}: {en_prompt}")
        if en_negative_prompt:
            app_logger.info(f"Negative prompt: {en_negative_prompt}")
        
        # Use varied seed for each scene (base seed + scene index) for diversity
        scene_seed = session.current_seed + i if session.current_seed != -1 else None
        img = generator.generate(en_prompt, negative_prompt=en_negative_prompt, seed=scene_seed, educational_mode=educational_mode)
        images.append(img)
        
    return images

def start_story(character_input, style_input, educational_mode, scene_count):
    """Initializes the story session."""
    session.reset()
    session.char_desc = character_input
    session.style = style_input
    session.educational_mode = educational_mode
    
    app_logger.info(f"Starting new session: {session.session_id}")
    app_logger.info(f"Character: {character_input}, Style: {style_input}, Educational: {educational_mode}, Scenes: {scene_count}")
    
    # Generate intro
    # Generate intro
    if educational_mode:
        intro_prompt = f"–¢–µ–º–∞ –∑–∞–Ω—è—Ç–∏—è: {character_input}. –°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è: {style_input}. –í–≤–µ–¥–µ–Ω–∏–µ:"
        intro_text = storyteller.generate_response("–õ–µ–∫—Ü–∏—è –Ω–∞—á–∞–ª–∞—Å—å.", intro_prompt, educational_mode=True)
        session.history = f"–°–∏—Å—Ç–µ–º–∞: –ó–∞–Ω—è—Ç–∏–µ –Ω–∞ —Ç–µ–º—É '{character_input}'.\n–õ–µ–∫—Ç–æ—Ä: {intro_text}"
    else:
        intro_prompt = f"–ò—Å—Ç–æ—Ä–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è. –ì–ª–∞–≤–Ω—ã–π –≥–µ—Ä–æ–π: {character_input}. –ñ–∞–Ω—Ä: {style_input}. –ù–∞—á–∞–ª–æ:"
        intro_text = storyteller.generate_response("–í—Å—Ç—É–ø–ª–µ–Ω–∏–µ:", intro_prompt, educational_mode=False)
        session.history = f"–°–∏—Å—Ç–µ–º–∞: –ò—Å—Ç–æ—Ä–∏—è –æ {character_input}.\n–ú–∞—Å—Ç–µ—Ä: {intro_text}"
    
    # Generate Sequence
    imgs = generate_sequence(intro_text, character_input, style_input, count=scene_count, educational_mode=educational_mode)
    session.images.extend(imgs)
    
    # Save session
    session_manager.save_session(
        session.session_id, 
        session.history, 
        session.char_desc, 
        session.style, 
        session.current_seed,
        session.educational_mode
    )
    
    # Return format: List of [User, Bot] dicts
    return [
        {"role": "assistant", "content": intro_text}
    ], imgs

def chat_turn(user_message, chat_history):
    """Handles a single turn of the chat."""
    if not user_message:
        return chat_history, None

    app_logger.info(f"User message: {user_message}")

    # Update history
    if session.educational_mode:
        session.history += f"\n–°—Ç—É–¥–µ–Ω—Ç: {user_message}"
    else:
        session.history += f"\n–ò–≥—Ä–æ–∫: {user_message}"
    
    # Generate Text Response
    response_text = storyteller.generate_response(session.history, user_message, educational_mode=session.educational_mode)
    
    if session.educational_mode:
        session.history += f"\n–õ–µ–∫—Ç–æ—Ä: {response_text}"
    else:
        session.history += f"\n–ú–∞—Å—Ç–µ—Ä: {response_text}"
    
    # Generate Sequence
    imgs = generate_sequence(response_text, session.char_desc, session.style, educational_mode=session.educational_mode)
    session.images.extend(imgs)
    
    # Update chat history
    chat_history.append({"role": "user", "content": user_message})
    chat_history.append({"role": "assistant", "content": response_text})
    
    # Save session
    session_manager.save_session(
        session.session_id, 
        session.history, 
        session.char_desc, 
        session.style, 
        session.current_seed,
        session.educational_mode
    )
    
    return chat_history, imgs

with gr.Blocks(title="Neuro Tale: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª–æ–≤", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üéì Neuro Tale: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–∑—É–∞–ª–æ–≤ –¥–ª—è IT-–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
    gr.Markdown("**–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É—á–µ–±–Ω–æ-–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ:**")
    gr.Markdown("- –ê–ª–≥–æ—Ä–∏—Ç–º–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é")
    gr.Markdown("- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö") 
    gr.Markdown("- –ú–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –∏ –ò–ò")
    gr.Markdown("- –†–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–º –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö")
    gr.Markdown("- –í–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")
    gr.Markdown("- –†–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤")
    
    with gr.Row():
        with gr.Column(scale=1):
            # Setup Column
            char_input = gr.Textbox(
                label="–¢–µ–º–∞ / –ö–æ–Ω—Ü–µ–ø—Ü–∏—è", 
                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–ê–ª–≥–æ—Ä–∏—Ç–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø—É–∑—ã—Ä—å–∫–æ–º', '–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏', '–°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'"
            )
            style_input = gr.Dropdown(
                label="–°—Ç–∏–ª—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", 
                choices=prompt_engineer.get_available_styles(), 
                value="Educational",
                info="–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Å—Ç–∏–ª—å –¥–ª—è IT-—Ç–µ–º—ã"
            )
            educational_checkbox = gr.Checkbox(
                label="–£—á–µ–±–Ω–æ-–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)", 
                value=True,
                info="–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–ª—è –ª–µ–∫—Ü–∏–π, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π –∏ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"
            )
            scene_count_slider = gr.Slider(
                label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                minimum=1,
                maximum=5,
                value=3,
                step=1,
                info="–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç 1 –¥–æ 5 —Å—Ü–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
            )
            low_memory_checkbox = gr.Checkbox(
                label="–†–µ–∂–∏–º –Ω–∏–∑–∫–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ (8GB RAM)", 
                value=True,
                info="–í–∫–ª—é—á–∏—Ç–µ –µ—Å–ª–∏ —É –≤–∞—Å 8GB –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏"
            )
            start_btn = gr.Button("üöÄ –°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å", variant="primary")
            
            # Current Scene Gallery
            scene_gallery = gr.Gallery(
                label="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å", 
                columns=[1], 
                rows=[3], 
                object_fit="contain", 
                height="auto"
            )
            
        with gr.Column(scale=2):
            # Chat Interface
            chatbot = gr.Chatbot(label="–ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –≤–∏–∑—É–∞–ª–∞–º", height=600)
            msg_input = gr.Textbox(
                label="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", 
                placeholder="–û–ø–∏—à–∏—Ç–µ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç–µ –¥–µ—Ç–∞–ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"
            )
            send_btn = gr.Button("–î–æ–ø–æ–ª–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å")

    # Events
    # Events
    start_btn.click(
        fn=start_story,
        inputs=[char_input, style_input, educational_checkbox, scene_count_slider],
        outputs=[chatbot, scene_gallery]
    )
    
    send_btn.click(
        fn=chat_turn,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, scene_gallery]
    )
    msg_input.submit(
        fn=chat_turn,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, scene_gallery]
    )

if __name__ == "__main__":
    demo.launch()
