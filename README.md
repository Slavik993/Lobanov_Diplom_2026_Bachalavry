# Интеллектуальная система генерации последовательности изображений по текстовому сюжету  
**Выпускная квалификационная работа (ВКР) 2026**

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Stable%20Diffusion-v1.5-orange?style=for-the-badge" alt="Stable Diffusion">
  <img src="https://img.shields.io/badge/Gradio-4.x-green?style=for-the-badge" alt="Gradio">
  <img src="https://img.shields.io/badge/Status-Готов%20к%20запуску-success?style=for-the-badge" alt="Status">
</p>

<p align="center">
  <img src="https://via.placeholder.com/800x400/1e1e2e/7f5af5?text=NeuroTale+-+Text+→+Storyboard" alt="NeuroTale Banner" width="800">
  <br><em>Пример сгенерированной раскадровки по текстовому сюжету</em>
</p>

## О проекте

**NeuroTale** — это локальная интеллектуальная система, которая автоматически превращает русскоязычный текстовый сюжет в последовательность стилистически согласованных изображений (раскадровку / сториборд / комикс-панели).

Разработана в рамках выпускной квалификационной работы бакалавра по направлению «Информационные системы и технологии» (МУИВ, 2026).

### Основные возможности

- Ввод текста на **русском языке** (неограниченная длина)
- Автоматический перевод на английский + улучшение промпта
- Семантическое разбиение сюжета на сцены (1–10 сцен)
- Выбор стиля генерации (кинематографичный, аниме, реализм, cyberpunk и др.)
- Генерация изображений на базе **Stable Diffusion 1.5** (локально, без API)
- Удобный веб-интерфейс на **Gradio**
- Автоматическое сохранение результатов (текст, промпты, изображения) в папку `outputs/`
- Полностью оффлайн после первой загрузки модели (~5 ГБ)

### Технологический стек

- **Язык**: Python 3.10+
- **Модель**: Stable Diffusion v1.5 (Hugging Face Diffusers)
- **Интерфейс**: Gradio
- **Перевод**: deep-translator (или NLLB при желании)
- **Зависимости**: torch, diffusers, transformers, accelerate, pillow
- **Хранение**: локальные папки + JSON-метаданные

## Демонстрация работы

https://github.com/Slavik993/Lobanov_Diplom_2026-/assets/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx  ← здесь можно вставить видео или гифку позже

Пример ввода:

Космический корабль терпит крушение на неизвестной планете. Астронавт выходит наружу и видит странные фиолетовые растения, которые начинают двигаться...

Результат: 4–8 последовательных кадров в едином стиле.

## Установка и запуск (30 секунд)

1. Клонируй репозиторий
```bash
git clone https://github.com/Slavik993/Lobanov_Diplom_2026-.git
cd Lobanov_Diplom_2026-

Создай виртуальное окружение (рекомендуется)

bash

python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/macOS:
source venv/bin/activate

Установи зависимости

bash

pip install -r requirements.txt

Запусти приложение

bash

python app.py

Открой в браузере: http://127.0.0.1:7860Первая загрузка модели займёт ~5–15 минут (зависит от интернета и GPU).Структура проекта

Lobanov_Diplom_2026-/
├── app.py                 # Главный файл с интерфейсом Gradio
├── requirements.txt       # Зависимости
├── core/
│   ├── translator.py      # Перевод текста
│   ├── text_processing.py # Разбиение на сцены + улучшение промптов
│   └── generator.py       # Генерация изображений (Stable Diffusion)
├── utils/
│   └── storage.py         # Сохранение сессий
├── outputs/               # Сгенерированные результаты (создаётся автоматически)
└── README.md

Требования к железуКомпонент
Минимально
Рекомендуется
ОС
Windows 10/11, Linux
Windows 11 / Ubuntu 22.04
CPU
Любой современный
Intel i5 / Ryzen 5+
RAM
16 ГБ
32 ГБ+
Видеокарта
Нет (медленно на CPU)
NVIDIA RTX 3060 6 ГБ+
Место на диске
~10 ГБ
20 ГБ+

На CPU генерация одного кадра занимает 30–120 секунд. На хорошей видеокарте — 3–10 секунд.Структура дипломной работыВведение
Глава 1. Анализ предметной области
Глава 2. Проектирование и реализация системы
Глава 3. Тестирование, интеграция и экономическая оценка
Заключение
Список литературы
Приложения (ТЗ, код, руководства)

